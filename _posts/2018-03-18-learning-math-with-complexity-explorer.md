---
layout: post
title: Learning math with Complexity Explorer
tags: Profesionaldevelopment Mathematics
---

Here is a (quick?) follow up on my post Bits, probability, and information - learning about information theory from last year. After learning about Information Theory, I decided to do a few more tutorials from the Complexity Explorer site. Read along to get inspired to explore on your own…
 <!--more-->
 

## Random Walks 
First, I signed up for a tutorial on Random Walks,

[https://www.complexityexplorer.org/tutorials/46-random-walks](https://www.complexityexplorer.org/tutorials/46-random-walks)

The topic covers the theoretical background for phenomena such as the motion of microscopic particles, such as bacteria or pollen grains, whose motion is governed by being buffeted by collisions with the molecules in a surrounding fluid.  Random walks also control many type of fluctuation phenomena that arise in finance. During the tutorial, we were introduced to stochastic differential equations, and how to solve the diffusion equation using Fourier transformations. The topics discussed were more advanced that what I normally see in MOOCs, but I really enjoyed spending some math quality time again. I haven’t done any calculus since completing the 2MA course at University of Copenhagen back in 1995.

 
## Differential Equations
 Inspired by learning about the diffusion differential equation, I decided to do the two tutorials on Differential Equations:

Introduction to Differential Equations: [https://www.complexityexplorer.org/tutorials/31-introduction-to-differential-equations](https://www.complexityexplorer.org/tutorials/31-introduction-to-differential-equations)

Ordinary Differential Equations: [https://www.complexityexplorer.org/tutorials/32-ordinary-differential-equations](https://www.complexityexplorer.org/tutorials/32-ordinary-differential-equations)

In the first one, focus was on building a geometric intuition of solutions to differential equations more than solving for exact solutions. The second one was an introduction to various numerical algorithms for solving differential equations. None of these topics were the focus when I learned about differential equations, so they complemented my understanding of the topic quite nicely.


## Renormalization 
Now, I jumped into something wild: Renormalization. I blogged about renormalization in this post http://www.pontop.dk/single-post/2016/07/25/My-favourite-video-shows-part-1-The-numberphile-channel

back in 2016, where I found it odd, that physicist in String Theory accepted that 1 + 2 + 3 + 4 + 5 + ... = -1/12. Therefore, I wanted to dig a little bit into the topic. Key learning point in the tutorial was that renormalization is the study of how (mathematical) theories evolve when the scale for units involved is changed. In the tutorial

Introduction to Renormalization: [https://www.complexityexplorer.org/tutorials/67-introduction-to-renormalization](https://www.complexityexplorer.org/tutorials/67-introduction-to-renormalization), we saw examples of how Markov chain models change (but stay within the model class) when the time scale is changed, and how Cellular Automata models change (and sometimes stay within the model class) when the time scale is changed. From physics, we were introduced to the Ising model and how a change of the length scale changes the model to something else, but where an approximation can turn it back to an Ising model again. Very interesting, even though we never got to the weird stuff in String Theory.  

 
## Maximum Entropy Methods
Finally, I did the tutorial on Maximum Entropy Methods: [https://www.complexityexplorer.org/tutorials/33-maximum-entropy-methods](https://www.complexityexplorer.org/tutorials/33-maximum-entropy-methods)

I first learned about this type of algorithm when I studied data mining. The way to construct a decision tree involves picking sub trees of maximum entropy, so I gave the tutorial a go. As for the introduction tutorial on differential equations, I think the main thing to be learned from this tutorial was to get an intuition for how different algorithms can produce models that fit data worse or better. Sometimes maximum entropy methods produce great models, sometimes a different approach is better.

 


All tutorials can be completed in 1-2 weeks, if you set aside 30 min of study time a day, you will be fine. Most of them only require high school math skills. I hope that I have inspired you to give one of them a go. The price of participation: FREE (you can make a small donation to the Sante Fe Institute if you like). In my opinion the learning outcome is… priceless (pun intended.)

 

Stay tuned for more math fun...

 

 

Read the original post on MOOC, Complexity Explorer and learning strategies here:

http://www.pontop.dk/single-post/2017/10/31/Bits-probability-and-information---learning-about-information-theory

 

Read more about all the Complexity Explorer tutorials here: [https://www.complexityexplorer.org/tutorials](https://www.complexityexplorer.org/tutorials)


 

 

Did you like the beautiful pictures? I got them all from pexels.com: 

    https://www.pexels.com/photo/addition-black-and-white-black-and-white-chalk-374918/  

    https://www.pexels.com/photo/bridge-child-children-fashion-191034/  

    https://www.pexels.com/photo/waterfall-deep-steep-4841/  

    https://www.pexels.com/photo/creepy-dark-fear-grave-534590/  

    https://www.pexels.com/photo/dawn-nature-tree-romania-56875/ 

